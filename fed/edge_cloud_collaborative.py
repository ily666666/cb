"""
è¾¹-äº‘ååŒæ¨ç†ç³»ç»Ÿ
Context-Aware Collaborative Inference for Edge-Cloud Systems

åŠŸèƒ½ï¼š
1. è¾¹ä¾§è½»é‡æ¨¡å‹ï¼ˆreal_resnet20å­¦ç”Ÿæ¨¡å‹ï¼‰è¿›è¡Œåˆæ­¥æ¨ç†
2. åŸºäºç½®ä¿¡åº¦é˜ˆå€¼åŠ¨æ€å†³å®šæ˜¯å¦ä¸Šä¼ åˆ°äº‘ç«¯
3. äº‘ä¾§å¼ºæ¨¡å‹ï¼ˆcomplex_resnet50æ•™å¸ˆæ¨¡å‹ï¼‰è¿›è¡Œæ·±åº¦æ¨ç†
4. è¯„ä¼°ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼ä¸‹çš„ç³»ç»Ÿæ€§èƒ½

é€‚é… project æ¡†æ¶ï¼š
- æ”¯æŒå¤šç§æ•°æ®é›†ï¼šads, radioml, reii, radar, rml2016, link11
- ä½¿ç”¨ project ä¸­çš„æ¨¡å‹ç»“æ„ï¼šreal_resnet20 (è¾¹ä¾§) å’Œ complex_resnet50 (äº‘ä¾§)
- å…¼å®¹ project çš„è¾“å…¥æ ¼å¼å’Œé¢„å¤„ç†é€»è¾‘

ä½¿ç”¨æ–¹æ³•ï¼š
    python edge_cloud_collaborative.py \\
        --dataset_type rml2016 \\
        --edge_model_path ./result/xxx/kd_trained_models/client_001_kd_model.pth \\
        --cloud_model_path ./result/xxx/pretrained_server_model.pth \\
        --data_path E:/BaiduNet_Download/rml2016.pkl \\
        --thresholds 0.5,0.6,0.7,0.8,0.9 \\
        --batch_size 32 \\
        --save_path result_collaborative

å¿…éœ€å‚æ•°ï¼š
    --edge_model_path: è¾¹ä¾§æ¨¡å‹è·¯å¾„ï¼ˆreal_resnet20å­¦ç”Ÿæ¨¡å‹ï¼‰
    --cloud_model_path: äº‘ä¾§æ¨¡å‹è·¯å¾„ï¼ˆcomplex_resnet50æ•™å¸ˆæ¨¡å‹ï¼‰

å¯é€‰å‚æ•°ï¼š
    --dataset_type: æ•°æ®é›†ç±»å‹ (ads, radioml, reii, radar, rml2016, link11)ï¼Œé»˜è®¤ ads
    --data_path: æ•°æ®é›†è·¯å¾„ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä¼šæ ¹æ®dataset_typeä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
    --num_classes: ç±»åˆ«æ•°ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä¼šæ ¹æ®æ•°æ®é›†ç±»å‹è‡ªåŠ¨ç¡®å®šï¼‰
    --batch_size: æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤ 32
    --thresholds: ç½®ä¿¡åº¦é˜ˆå€¼åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œé»˜è®¤ '0.5,0.6,0.7,0.8,0.9'
    --num_batches: è¯„ä¼°æ‰¹æ¬¡æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰ï¼Œé»˜è®¤ None
    --cloud_latency_ms: äº‘ç«¯æ¨ç†å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤ 50.0
    --bandwidth_mbps: å¸¦å®½ï¼ˆMbpsï¼‰ï¼Œé»˜è®¤ 100.0
    --image_size_mb: å›¾åƒå¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤ 0.1
    --save_path: ç»“æœä¿å­˜è·¯å¾„ï¼Œé»˜è®¤ 'result_edge_cloud_collaborative'

ç¤ºä¾‹ï¼š
    1. RML2016æ•°æ®é›†ï¼š
       python edge_cloud_collaborative.py \\
           --dataset_type rml2016 \\
           --edge_model_path ./result/xxx/kd_trained_models/client_001_kd_model.pth \\
           --cloud_model_path ./result/xxx/pretrained_server_model.pth

    2. Link11æ•°æ®é›†ï¼š
       python edge_cloud_collaborative.py \\
           --dataset_type link11 \\
           --edge_model_path ./result/xxx/kd_trained_models/client_001_kd_model.pth \\
           --cloud_model_path ./result/xxx/pretrained_server_model.pth \\
           --thresholds 0.6,0.7,0.8 \\
           --num_batches 50

    3. å¿«é€Ÿæµ‹è¯•ï¼ˆåªè¯„ä¼°50ä¸ªæ‰¹æ¬¡ï¼‰ï¼š
       python edge_cloud_collaborative.py \\
           --dataset_type rml2016 \\
           --edge_model_path ./result/xxx/kd_trained_models/client_001_kd_model.pth \\
           --cloud_model_path ./result/xxx/pretrained_server_model.pth \\
           --num_batches 50
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm


class EdgeCloudCollaborativeInference:
    """
    è¾¹-äº‘ååŒæ¨ç†ç³»ç»Ÿ
    
    æ ¸å¿ƒæœºåˆ¶ï¼š
    - è¾¹ä¾§æ¨¡å‹è®¡ç®—ç½®ä¿¡åº¦ p_max = max(Softmax(z))
    - è‹¥ p_max >= Tï¼šè¾¹ä¾§ç›´æ¥è¾“å‡º
    - è‹¥ p_max < Tï¼šä¸Šä¼ åˆ°äº‘ç«¯æ·±åº¦æ¨ç†
    """
    
    def __init__(self, edge_model, cloud_model, device, dataset_type='ads',
                 cloud_latency_ms=50.0, bandwidth_mbps=100.0, 
                 image_size_mb=0.1):
        """
        åˆå§‹åŒ–è¾¹-äº‘ååŒæ¨ç†ç³»ç»Ÿ
        
        Args:
            edge_model: è¾¹ä¾§è½»é‡æ¨¡å‹ï¼ˆreal_resnet20å­¦ç”Ÿæ¨¡å‹ï¼‰
            cloud_model: äº‘ä¾§å¼ºæ¨¡å‹ï¼ˆcomplex_resnet50æ•™å¸ˆæ¨¡å‹ï¼‰
            device: è®¡ç®—è®¾å¤‡
            dataset_type: æ•°æ®é›†ç±»å‹ï¼ˆç”¨äºç¡®å®šè¾“å…¥é¢„å¤„ç†æ–¹å¼ï¼‰
            cloud_latency_ms: äº‘ç«¯æ¨ç†å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ï¼Œæ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ+æ¨ç†æ—¶é—´
            bandwidth_mbps: å¸¦å®½ï¼ˆMbpsï¼‰ï¼Œç”¨äºè®¡ç®—ä¼ è¾“æ—¶é—´
            image_size_mb: å›¾åƒå¤§å°ï¼ˆMBï¼‰ï¼Œç”¨äºè®¡ç®—ä¼ è¾“æ—¶é—´
        """
        self.edge_model = edge_model
        self.cloud_model = cloud_model
        self.device = device
        self.dataset_type = dataset_type
        
        # æ¨¡æ‹Ÿç½‘ç»œå‚æ•°
        self.cloud_latency_ms = cloud_latency_ms
        self.bandwidth_mbps = bandwidth_mbps
        self.image_size_mb = image_size_mb
        
        # ä¸åŒæ•°æ®é›†çš„è¾“å…¥é•¿åº¦æ˜ å°„
        self.input_length_map = {
            'ads': 4096,
            'radioml': 128,
            'reii': 2000,
            'radar': 500,
            'rml2016': 600,
            'link11': 1024
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'edge_correct': 0,
            'edge_total': 0,
            'cloud_correct': 0,
            'cloud_total': 0,
            'edge_inference_time': [],
            'cloud_inference_time': [],
            'total_time': []
        }
        
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        self.edge_model.eval()
        self.cloud_model.eval()
    
    def compute_confidence(self, logits: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—ç½®ä¿¡åº¦ï¼ˆsoftmaxæœ€å¤§æ¦‚ç‡ï¼‰
        
        Args:
            logits: æ¨¡å‹è¾“å‡ºçš„logits [batch_size, num_classes]
        
        Returns:
            æœ€å¤§æ¦‚ç‡å€¼ [batch_size]
        """
        probs = F.softmax(logits, dim=1)
        p_max, _ = torch.max(probs, dim=1)
        return p_max
    
    def preprocess_for_edge_model(self, inputs: torch.Tensor) -> torch.Tensor:
        """
        ä¸ºè¾¹ä¾§æ¨¡å‹é¢„å¤„ç†è¾“å…¥ï¼ˆreal_resnet20ï¼‰
        real_resnet20æ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†å¤æ•°è¾“å…¥ï¼Œè½¬æ¢ä¸º2é€šé“å®æ•°
        
        Args:
            inputs: è¾“å…¥æ•°æ®ï¼ˆå¯èƒ½æ˜¯å¤æ•°æˆ–å®æ•°ï¼Œå„ç§å½¢çŠ¶ï¼‰
        
        Returns:
            é¢„å¤„ç†åçš„è¾“å…¥ï¼ˆå¤æ•°å¼ é‡ï¼Œshape: [batch_size, length]ï¼‰
        """
        # RML2016æ•°æ®é›†ï¼šè¾“å…¥å·²ç»æ˜¯ (batch_size, 600) å¤æ•°ï¼Œç›´æ¥è¿”å›
        if self.dataset_type == 'rml2016':
            # ç¡®ä¿åœ¨è®¾å¤‡ä¸Š
            inputs = inputs.to(self.device)
            # ç¡®ä¿æ˜¯å¤æ•°æ ¼å¼ï¼ˆRML2016Datasetè¿”å›çš„å·²ç»æ˜¯å¤æ•°ï¼‰
            if not torch.is_complex(inputs):
                # å¦‚æœæ˜¯å®æ•°ï¼Œè½¬æ¢ä¸ºå¤æ•°ï¼ˆè™šéƒ¨ä¸º0ï¼‰
                if inputs.dim() == 2:
                    inputs_imag = torch.zeros_like(inputs)
                    inputs = torch.view_as_complex(torch.stack([inputs, inputs_imag], dim=-1))
            return inputs
        
        # å…¶ä»–æ•°æ®é›†çš„é¢„å¤„ç†é€»è¾‘
        # ç¡®ä¿è¾“å…¥æ˜¯å¤æ•°æ ¼å¼
        if not torch.is_complex(inputs):
            if inputs.dim() == 2:
                # [batch, length] -> è½¬ä¸ºå¤æ•°
                inputs_real = inputs
                inputs_imag = torch.zeros_like(inputs_real)
                inputs = torch.view_as_complex(torch.stack([inputs_real, inputs_imag], dim=-1))
            elif inputs.dim() == 3:
                # [batch, 2, length] -> è½¬ä¸ºå¤æ•°
                if inputs.shape[1] == 2:
                    inputs = torch.view_as_complex(torch.stack([inputs[:, 0], inputs[:, 1]], dim=-1))
                else:
                    inputs_real = inputs[:, 0, :] if inputs.shape[1] > 0 else inputs.squeeze(1)
                    inputs_imag = torch.zeros_like(inputs_real)
                    inputs = torch.view_as_complex(torch.stack([inputs_real, inputs_imag], dim=-1))
        
        # ç¡®ä¿shapeæ˜¯ [batch_size, length]
        if inputs.dim() == 3:
            batch_size, channels, length = inputs.shape
            if channels == 1:
                inputs = inputs.squeeze(1)
            else:
                # å–ç¬¬ä¸€ä¸ªé€šé“æˆ–åˆå¹¶
                inputs = inputs[:, 0, :] if channels > 0 else inputs.mean(dim=1)
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        inputs = inputs.to(self.device)
        
        return inputs
    
    def preprocess_for_cloud_model(self, inputs: torch.Tensor) -> torch.Tensor:
        """
        ä¸ºäº‘ä¾§æ¨¡å‹é¢„å¤„ç†è¾“å…¥ï¼ˆcomplex_resnet50ï¼‰
        complex_resnet50æ¨¡å‹éœ€è¦1é€šé“å¤æ•°è¾“å…¥ [batch, 1, H, W]
        
        Args:
            inputs: è¾“å…¥æ•°æ®ï¼ˆå¯èƒ½æ˜¯å¤æ•°æˆ–å®æ•°ï¼Œå„ç§å½¢çŠ¶ï¼‰
        
        Returns:
            é¢„å¤„ç†åçš„è¾“å…¥ï¼ˆå¤æ•°å¼ é‡ï¼Œshape: [batch, 1, H, W]ï¼‰
        """
        # ç§»åŠ¨åˆ°è®¾å¤‡
        inputs = inputs.to(self.device)
        
        # å¤„ç†ä¸åŒæ•°æ®é›†çš„è¾“å…¥æ ¼å¼
        if self.dataset_type == 'rml2016':
            # RML2016: è¾“å…¥åº”è¯¥æ˜¯ (batch_size, 600) å¤æ•°
            # complex_resnet50_rml2016 æœŸæœ› (batch_size, 600) å¤æ•°ï¼Œç„¶åå†…éƒ¨ä¼š reshape ä¸º (batch_size, 1, 20, 30)
            if inputs.dim() == 2:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¤æ•°
                if not torch.is_complex(inputs):
                    # å¦‚æœæ˜¯å®æ•°ï¼Œå¯èƒ½æ˜¯ (batch_size, 600) æˆ– (batch_size, 1200)
                    # éœ€è¦è½¬æ¢ä¸ºå¤æ•°
                    if inputs.shape[1] == 600:
                        # (batch_size, 600) å®æ•° -> (batch_size, 600) å¤æ•°ï¼ˆè™šéƒ¨ä¸º0ï¼‰
                        inputs_imag = torch.zeros_like(inputs)
                        inputs = torch.view_as_complex(torch.stack([inputs, inputs_imag], dim=-1))
                    elif inputs.shape[1] == 1200:
                        # (batch_size, 1200) å¯èƒ½æ˜¯ flattened çš„ (batch_size, 2, 600)
                        # reshape ä¸º (batch_size, 2, 600) ç„¶åè½¬æ¢ä¸ºå¤æ•°
                        inputs = inputs.view(inputs.shape[0], 2, 600)
                        inputs = torch.view_as_complex(torch.stack([inputs[:, 0], inputs[:, 1]], dim=-1))
                # ç¡®ä¿é•¿åº¦æ˜¯ 600
                if inputs.shape[1] != 600:
                    # å¦‚æœé•¿åº¦ä¸å¯¹ï¼Œå°è¯• reshape æˆ–æˆªæ–­/å¡«å……
                    if inputs.shape[1] > 600:
                        inputs = inputs[:, :600]
                    else:
                        # å¡«å……åˆ° 600
                        pad_length = 600 - inputs.shape[1]
                        inputs = torch.nn.functional.pad(inputs, (0, pad_length), mode='constant', value=0)
                return inputs
            elif inputs.dim() == 3:
                # å¯èƒ½æ˜¯ (batch_size, 2, 600) å®æ•°ï¼Œéœ€è¦è½¬æ¢ä¸ºå¤æ•°
                if inputs.shape[2] == 600:
                    if inputs.shape[1] == 2:
                        # (batch_size, 2, 600) -> (batch_size, 600) å¤æ•°
                        inputs = torch.view_as_complex(torch.stack([inputs[:, 0], inputs[:, 1]], dim=-1))
                    elif inputs.shape[1] == 1:
                        # (batch_size, 1, 600) -> (batch_size, 600) å¤æ•°ï¼ˆè™šéƒ¨ä¸º0ï¼‰
                        inputs = inputs.squeeze(1)
                        inputs_imag = torch.zeros_like(inputs)
                        inputs = torch.view_as_complex(torch.stack([inputs, inputs_imag], dim=-1))
                return inputs
            else:
                # å…¶ä»–ç»´åº¦ï¼Œå°è¯• flatten æˆ– reshape
                inputs = inputs.flatten(start_dim=1)
                if inputs.shape[1] > 600:
                    inputs = inputs[:, :600]
                elif inputs.shape[1] < 600:
                    pad_length = 600 - inputs.shape[1]
                    inputs = torch.nn.functional.pad(inputs, (0, pad_length), mode='constant', value=0)
                # è½¬æ¢ä¸ºå¤æ•°
                if not torch.is_complex(inputs):
                    inputs_imag = torch.zeros_like(inputs)
                    inputs = torch.view_as_complex(torch.stack([inputs, inputs_imag], dim=-1))
                return inputs
        
        # å…¶ä»–æ•°æ®é›†çš„é¢„å¤„ç†é€»è¾‘
        # ç¡®ä¿è¾“å…¥æ˜¯å¤æ•°æ ¼å¼
        if not torch.is_complex(inputs):
            if inputs.dim() == 2:
                inputs_real = inputs
                inputs_imag = torch.zeros_like(inputs_real)
                inputs = torch.view_as_complex(torch.stack([inputs_real, inputs_imag], dim=-1))
            elif inputs.dim() == 3:
                if inputs.shape[1] == 2:
                    inputs = torch.view_as_complex(torch.stack([inputs[:, 0], inputs[:, 1]], dim=-1))
        
        # ç¡®å®šç›®æ ‡2Då°ºå¯¸ï¼ˆæ ¹æ®æ•°æ®é›†ç±»å‹ï¼‰
        target_length = self.input_length_map.get(self.dataset_type, 4096)
        min_size = 32
        
        if inputs.dim() == 2:
            # [batch, length] -> [batch, 1, H, W]
            batch_size = inputs.shape[0]
            length = inputs.shape[1]
            
            # è®¡ç®—2Då°ºå¯¸
            if length == 4096:
                h, w = 64, 64
            elif length == 128:
                h, w = 8, 16
            elif length == 2000:
                h, w = 40, 50
            elif length == 500:
                h, w = 20, 25
            elif length == 600:
                h, w = 20, 30
            elif length == 1024:
                h, w = 32, 32
            else:
                # è‡ªåŠ¨è®¡ç®—
                import math
                sqrt_len = int(math.sqrt(length))
                h, w = sqrt_len, sqrt_len
                for h_candidate in range(sqrt_len, 0, -1):
                    if length % h_candidate == 0:
                        h = h_candidate
                        w = length // h_candidate
                        if h >= min_size and w >= min_size:
                            break
                if h < min_size or w < min_size:
                    h, w = min_size, (length + min_size - 1) // min_size
                    target_size = h * w
                    if target_size > length:
                        pad_length = target_size - length
                        inputs = torch.nn.functional.pad(inputs, (0, pad_length), mode='constant', value=0)
            
            inputs = inputs.view(batch_size, 1, h, w)
            
        elif inputs.dim() == 3:
            # [batch, channels, length] -> [batch, 1, H, W]
            batch_size, channels, length = inputs.shape
            if channels != 1:
                if channels > 1:
                    inputs = inputs[:, 0:1, :]  # å–ç¬¬ä¸€ä¸ªé€šé“
            
            # è®¡ç®—2Då°ºå¯¸ï¼ˆåŒä¸Šé€»è¾‘ï¼‰
            if length == 4096:
                h, w = 64, 64
            elif length == 128:
                h, w = 8, 16
            elif length == 2000:
                h, w = 40, 50
            elif length == 500:
                h, w = 20, 25
            elif length == 600:
                h, w = 20, 30
            elif length == 1024:
                h, w = 32, 32
            else:
                import math
                sqrt_len = int(math.sqrt(length))
                h, w = sqrt_len, sqrt_len
                for h_candidate in range(sqrt_len, 0, -1):
                    if length % h_candidate == 0:
                        h = h_candidate
                        w = length // h_candidate
                        if h >= min_size and w >= min_size:
                            break
                if h < min_size or w < min_size:
                    h, w = min_size, (length + min_size - 1) // min_size
                    target_size = h * w
                    if target_size > length:
                        pad_length = target_size - length
                        inputs = torch.nn.functional.pad(inputs, (0, pad_length), mode='constant', value=0)
            
            inputs = inputs.view(batch_size, h, w).unsqueeze(1)
        
        # å¦‚æœå°ºå¯¸å¤ªå°ï¼Œè¿›è¡Œæ’å€¼
        if inputs.shape[2] < min_size or inputs.shape[3] < min_size:
            input_real = torch.cat([inputs.real, inputs.imag], dim=1)
            input_real = torch.nn.functional.interpolate(
                input_real, size=(min_size, min_size), mode='bilinear', align_corners=False
            )
            inputs = torch.view_as_complex(
                torch.stack([input_real[:, 0], input_real[:, 1]], dim=-1)
            )
            inputs = inputs.unsqueeze(1)
        
        return inputs
    
    def edge_inference(self, inputs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, float]:
        """
        è¾¹ä¾§æ¨ç†ï¼ˆreal_resnet20å­¦ç”Ÿæ¨¡å‹ï¼‰
        ä½¿ç”¨ä¸è®­ç»ƒä»£ç ç›¸åŒçš„è¾“å…¥å¤„ç†æ–¹å¼
        
        Args:
            inputs: è¾“å…¥æ•°æ®ï¼ˆå¯¹äºRML2016ï¼Œåº”è¯¥æ˜¯ (batch_size, 600) å¤æ•°ï¼‰
        
        Returns:
            logits: æ¨¡å‹è¾“å‡ºlogits
            predictions: é¢„æµ‹ç±»åˆ«
            inference_time: æ¨ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        start_time = time.time()
        
        with torch.no_grad():
            # RML2016æ•°æ®é›†ï¼šè¾“å…¥å·²ç»æ˜¯ (batch_size, 600) å¤æ•°ï¼Œç›´æ¥ä½¿ç”¨
            # å…¶ä»–æ•°æ®é›†ï¼šéœ€è¦é¢„å¤„ç†
            if self.dataset_type == 'rml2016':
                # ç¡®ä¿åœ¨è®¾å¤‡ä¸Šä¸”æ˜¯å¤æ•°æ ¼å¼
                processed_inputs = inputs.to(self.device)
                if not torch.is_complex(processed_inputs):
                    # å¦‚æœæ˜¯å®æ•°ï¼Œè½¬æ¢ä¸ºå¤æ•°ï¼ˆè™šéƒ¨ä¸º0ï¼‰
                    inputs_imag = torch.zeros_like(processed_inputs)
                    processed_inputs = torch.view_as_complex(torch.stack([processed_inputs, inputs_imag], dim=-1))
            else:
                # å…¶ä»–æ•°æ®é›†ï¼šä½¿ç”¨é¢„å¤„ç†å‡½æ•°
                processed_inputs = self.preprocess_for_edge_model(inputs)
            
            # è¾¹ä¾§æ¨¡å‹æ¨ç†ï¼ˆæ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†å¤æ•°->å®æ•°è½¬æ¢ï¼‰
            # real_resnet20_rml2016 çš„ forward æ–¹æ³•æœŸæœ› (batch_size, 600) å¤æ•°
            logits = self.edge_model(processed_inputs)
            
            # å¤„ç†å¤æ•°è¾“å‡ºï¼ˆå¦‚æœæœ‰ï¼‰
            if torch.is_complex(logits):
                logits = torch.abs(logits)
            
            predictions = torch.argmax(logits, dim=1)
        
        inference_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return logits, predictions, inference_time
    
    def cloud_inference(self, inputs: torch.Tensor) -> Tuple[torch.Tensor, float]:
        """
        äº‘ä¾§æ¨ç†ï¼ˆcomplex_resnet50æ•™å¸ˆæ¨¡å‹ï¼‰
        ä½¿ç”¨ä¸è®­ç»ƒä»£ç ç›¸åŒçš„è¾“å…¥å¤„ç†æ–¹å¼
        
        Args:
            inputs: è¾“å…¥æ•°æ®ï¼ˆå¯¹äºRML2016ï¼Œåº”è¯¥æ˜¯ (batch_size, 600) å¤æ•°ï¼‰
        
        Returns:
            predictions: é¢„æµ‹ç±»åˆ«
            total_time: æ€»æ—¶é—´ï¼ˆä¼ è¾“+æ¨ç†ï¼Œæ¯«ç§’ï¼‰
        """
        batch_size = inputs.shape[0]
        
        # æ¨¡æ‹Ÿä¼ è¾“æ—¶é—´ï¼ˆæ‰¹é‡ä¼ è¾“ï¼‰
        single_sample_transmission_ms = (self.image_size_mb * 8) / self.bandwidth_mbps * 1000
        transmission_time_ms = single_sample_transmission_ms  # æ‰¹é‡ä¼ è¾“ï¼Œæ—¶é—´ä¸ç´¯åŠ 
        
        # äº‘ç«¯æ¨ç†æ—¶é—´
        start_time = time.time()
        with torch.no_grad():
            # RML2016æ•°æ®é›†ï¼šè¾“å…¥å·²ç»æ˜¯ (batch_size, 600) å¤æ•°ï¼Œç›´æ¥ä½¿ç”¨
            # å…¶ä»–æ•°æ®é›†ï¼šéœ€è¦é¢„å¤„ç†
            if self.dataset_type == 'rml2016':
                # ç¡®ä¿åœ¨è®¾å¤‡ä¸Šä¸”æ˜¯å¤æ•°æ ¼å¼
                processed_inputs = inputs.to(self.device)
                if not torch.is_complex(processed_inputs):
                    # å¦‚æœæ˜¯å®æ•°ï¼Œè½¬æ¢ä¸ºå¤æ•°ï¼ˆè™šéƒ¨ä¸º0ï¼‰
                    inputs_imag = torch.zeros_like(processed_inputs)
                    processed_inputs = torch.view_as_complex(torch.stack([processed_inputs, inputs_imag], dim=-1))
            else:
                # å…¶ä»–æ•°æ®é›†ï¼šä½¿ç”¨é¢„å¤„ç†å‡½æ•°
                processed_inputs = self.preprocess_for_cloud_model(inputs)
            
            # äº‘ä¾§æ¨¡å‹æ¨ç†
            # complex_resnet50_rml2016 çš„ forward æ–¹æ³•æœŸæœ› (batch_size, 600) å¤æ•°
            logits = self.cloud_model(processed_inputs)
            
            # å¤„ç†å¤æ•°è¾“å‡º
            if torch.is_complex(logits):
                logits = torch.abs(logits)
            
            predictions = torch.argmax(logits, dim=1)
        
        inference_time_ms = (time.time() - start_time) * 1000
        total_time_ms = transmission_time_ms + inference_time_ms + self.cloud_latency_ms
        
        return predictions, total_time_ms
    
    def context_aware_inference(self, inputs: torch.Tensor, targets: torch.Tensor, 
                                threshold: float) -> Dict:
        """
        ä¸Šä¸‹æ–‡æ„ŸçŸ¥ååŒæ¨ç†ï¼ˆæ ¸å¿ƒå‡½æ•°ï¼‰
        
        Args:
            inputs: è¾“å…¥æ•°æ®
            targets: çœŸå®æ ‡ç­¾
            threshold: ç½®ä¿¡åº¦é˜ˆå€¼ T
        
        Returns:
            æ¨ç†ç»“æœå­—å…¸
        """
        batch_size = inputs.shape[0]
        results = {
            'predictions': torch.zeros(batch_size, dtype=torch.long, device=self.device),
            'sources': [],  # 'edge' æˆ– 'cloud'
            'confidences': [],
            'edge_correct': 0,
            'cloud_correct': 0,
            'edge_count': 0,
            'cloud_count': 0,
            'edge_time': 0.0,
            'cloud_time': 0.0,
            'total_time': 0.0
        }
        
        # è¾¹ä¾§æ¨ç†
        logits_edge, preds_edge, edge_time = self.edge_inference(inputs)
        confidences = self.compute_confidence(logits_edge)
        
        # å†³å®šå“ªäº›æ ·æœ¬ä¸Šä¼ åˆ°äº‘ç«¯
        cloud_mask = confidences < threshold
        edge_mask = ~cloud_mask
        
        # è¾¹ä¾§ç›´æ¥è¾“å‡º
        if edge_mask.any():
            edge_indices = torch.where(edge_mask)[0]
            results['predictions'][edge_indices] = preds_edge[edge_indices]
            results['edge_count'] = edge_mask.sum().item()
            results['edge_correct'] = (preds_edge[edge_indices] == targets[edge_indices]).sum().item()
            results['edge_time'] = edge_time
            results['sources'].extend(['edge'] * results['edge_count'])
            results['confidences'].extend(confidences[edge_indices].cpu().tolist())
        
        # äº‘ç«¯æ·±åº¦æ¨ç†
        if cloud_mask.any():
            cloud_indices = torch.where(cloud_mask)[0]
            cloud_inputs = inputs[cloud_indices]
            cloud_targets = targets[cloud_indices]
            
            preds_cloud, cloud_time = self.cloud_inference(cloud_inputs)
            results['predictions'][cloud_indices] = preds_cloud
            results['cloud_count'] = cloud_mask.sum().item()
            results['cloud_correct'] = (preds_cloud == cloud_targets).sum().item()
            results['cloud_time'] = cloud_time
            results['sources'].extend(['cloud'] * results['cloud_count'])
            results['confidences'].extend(confidences[cloud_indices].cpu().tolist())
        
        # è®¡ç®—æ€»æ—¶é—´
        results['total_time'] = results['edge_time'] + results['cloud_time']
        
        return results
    
    def evaluate(self, dataloader, threshold: float, num_batches: Optional[int] = None) -> Dict:
        """
        è¯„ä¼°ç³»ç»Ÿæ€§èƒ½
        
        Args:
            dataloader: æ•°æ®åŠ è½½å™¨
            threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            num_batches: è¯„ä¼°çš„æ‰¹æ¬¡æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰
        
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        self.stats = {
            'edge_correct': 0,
            'edge_total': 0,
            'cloud_correct': 0,
            'cloud_total': 0,
            'edge_inference_time': [],
            'cloud_inference_time': [],
            'total_time': [],
            'confidences': []
        }
        
        total_correct = 0
        total_samples = 0
        
        print(f"\nè¯„ä¼°ç½®ä¿¡åº¦é˜ˆå€¼ T = {threshold:.2f}...")
        if num_batches is not None:
            print(f"  å°†è¯„ä¼° {num_batches} ä¸ªæ‰¹æ¬¡ï¼ˆçº¦ {num_batches * dataloader.batch_size} æ ·æœ¬ï¼‰")
        
        batch_count = 0
        total_batches = len(dataloader) if num_batches is None else min(num_batches, len(dataloader))
        
        for batch_idx, batch in enumerate(dataloader):
            if num_batches is not None and batch_count >= num_batches:
                break
            
            # å¤„ç†batchæ ¼å¼ï¼ˆå…¼å®¹ä¸åŒæ•°æ®é›†çš„è¿”å›æ ¼å¼ï¼‰
            if len(batch) == 3:
                inputs, targets, _ = batch
            elif len(batch) == 2:
                inputs, targets = batch
            else:
                continue
            
            inputs = inputs.to(self.device)
            targets = targets.to(self.device)
            
            # ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†
            results = self.context_aware_inference(inputs, targets, threshold)
            
            # ç»Ÿè®¡å‡†ç¡®ç‡
            batch_correct = (results['predictions'] == targets).sum().item()
            total_correct += batch_correct
            total_samples += targets.size(0)
            
            # ç»Ÿè®¡è¾¹ä¾§å’Œäº‘ä¾§
            self.stats['edge_correct'] += results['edge_correct']
            self.stats['edge_total'] += results['edge_count']
            self.stats['cloud_correct'] += results['cloud_correct']
            self.stats['cloud_total'] += results['cloud_count']
            
            # ç»Ÿè®¡æ—¶é—´
            if results['edge_time'] > 0:
                self.stats['edge_inference_time'].append(results['edge_time'])
            if results['cloud_time'] > 0:
                self.stats['cloud_inference_time'].append(results['cloud_time'])
            self.stats['total_time'].append(results['total_time'])
            self.stats['confidences'].extend(results['confidences'])
            
            batch_count += 1
            
            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == total_batches:
                progress = 100 * (batch_idx + 1) / total_batches if total_batches > 0 else 0
                print(f"  è¿›åº¦: {progress:.1f}% ({batch_idx + 1}/{total_batches} æ‰¹æ¬¡) | "
                      f"å‡†ç¡®ç‡ {100 * total_correct / total_samples:.2f}% | "
                      f"è¾¹ä¾§ {self.stats['edge_total']}, äº‘ä¾§ {self.stats['cloud_total']}")
        
        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        overall_accuracy = 100 * total_correct / total_samples if total_samples > 0 else 0
        edge_accuracy = 100 * self.stats['edge_correct'] / self.stats['edge_total'] if self.stats['edge_total'] > 0 else 0
        cloud_accuracy = 100 * self.stats['cloud_correct'] / self.stats['cloud_total'] if self.stats['cloud_total'] > 0 else 0
        cloud_ratio = self.stats['cloud_total'] / total_samples if total_samples > 0 else 0
        
        # è®¡ç®—å¹³å‡æ—¶é—´ï¼ˆæŒ‰batchï¼‰
        avg_edge_time_batch = np.mean(self.stats['edge_inference_time']) if self.stats['edge_inference_time'] else 0
        avg_cloud_time_batch = np.mean(self.stats['cloud_inference_time']) if self.stats['cloud_inference_time'] else 0
        avg_total_time_batch = np.mean(self.stats['total_time']) if self.stats['total_time'] else 0
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å¹³å‡æ—¶é—´
        if total_samples > 0 and len(self.stats['total_time']) > 0:
            estimated_batch_size = total_samples / len(self.stats['total_time'])
            avg_edge_time_per_sample = avg_edge_time_batch / estimated_batch_size if estimated_batch_size > 0 else avg_edge_time_batch
            
            if self.stats['cloud_total'] > 0 and len(self.stats['cloud_inference_time']) > 0:
                avg_cloud_samples_per_batch = self.stats['cloud_total'] / len(self.stats['cloud_inference_time'])
                avg_cloud_time_per_sample = avg_cloud_time_batch / avg_cloud_samples_per_batch if avg_cloud_samples_per_batch > 0 else avg_cloud_time_batch
            else:
                avg_cloud_time_per_sample = 0
            
            if total_samples > 0:
                avg_per_sample_latency = (
                    self.stats['edge_total'] * avg_edge_time_per_sample + 
                    self.stats['cloud_total'] * avg_cloud_time_per_sample
                ) / total_samples
            else:
                avg_per_sample_latency = avg_edge_time_per_sample
            
            avg_total_time_per_sample = avg_per_sample_latency
        else:
            estimated_batch_size = 0
            avg_edge_time_per_sample = avg_edge_time_batch
            avg_cloud_time_per_sample = avg_cloud_time_batch if avg_cloud_time_batch > 0 else 0
            avg_per_sample_latency = avg_edge_time_per_sample
            avg_total_time_per_sample = avg_per_sample_latency
        
        # è®¡ç®—é€Ÿåº¦æå‡
        if avg_per_sample_latency > 0 and avg_cloud_time_per_sample > 0:
            speedup_ratio = avg_cloud_time_per_sample / avg_per_sample_latency
            speedup_percentage = (1 - avg_per_sample_latency / avg_cloud_time_per_sample) * 100
        else:
            speedup_ratio = 0
            speedup_percentage = 0
        
        results_summary = {
            'threshold': threshold,
            'overall_accuracy': overall_accuracy,
            'edge_accuracy': edge_accuracy,
            'cloud_accuracy': cloud_accuracy,
            'edge_total': self.stats['edge_total'],
            'cloud_total': self.stats['cloud_total'],
            'cloud_ratio': cloud_ratio,
            'avg_edge_time_ms_batch': avg_edge_time_batch,
            'avg_cloud_time_ms_batch': avg_cloud_time_batch,
            'avg_total_time_ms_batch': avg_total_time_batch,
            'avg_edge_time_ms': avg_edge_time_per_sample,
            'avg_cloud_time_ms': avg_cloud_time_per_sample,
            'avg_total_time_ms': avg_total_time_batch,
            'avg_total_time_ms_per_sample': avg_total_time_per_sample,
            'avg_per_sample_latency_ms': avg_per_sample_latency,
            'estimated_batch_size': estimated_batch_size,
            'speedup_ratio': speedup_ratio,
            'speedup_percentage': speedup_percentage,
            'total_samples': total_samples
        }
        
        return results_summary


def plot_collaborative_results(results_list: List[Dict], save_path: str):
    """
    ç»˜åˆ¶ååŒæ¨ç†å®éªŒç»“æœ
    
    Args:
        results_list: ä¸åŒé˜ˆå€¼ä¸‹çš„ç»“æœåˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
    """
    import matplotlib.pyplot as plt
    import seaborn as sns
    import os
    
    thresholds = [r['threshold'] for r in results_list]
    accuracies = [r['overall_accuracy'] for r in results_list]
    cloud_ratios = [r['cloud_ratio'] for r in results_list]
    edge_accs = [r['edge_accuracy'] for r in results_list]
    cloud_accs = [r['cloud_accuracy'] for r in results_list]
    avg_times = [r['avg_total_time_ms'] for r in results_list]
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1. å‡†ç¡®ç‡ vs äº‘ç«¯è°ƒç”¨ç‡
    ax1 = axes[0, 0]
    ax1_twin = ax1.twinx()
    line1 = ax1.plot(thresholds, accuracies, 'b-o', label='Overall Accuracy', linewidth=2)
    line2 = ax1_twin.plot(thresholds, cloud_ratios, 'r-s', label='Cloud Ratio', linewidth=2)
    ax1.set_xlabel('Confidence Threshold T', fontsize=12)
    ax1.set_ylabel('Accuracy (%)', fontsize=12, color='b')
    ax1_twin.set_ylabel('Cloud Offloading Ratio', fontsize=12, color='r')
    ax1.tick_params(axis='y', labelcolor='b')
    ax1_twin.tick_params(axis='y', labelcolor='r')
    ax1.grid(True, alpha=0.3)
    ax1.set_title('Accuracy vs Cloud Offloading Ratio', fontsize=14, fontweight='bold')
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax1.legend(lines, labels, loc='upper left')
    
    # 2. è¾¹ä¾§å’Œäº‘ä¾§å‡†ç¡®ç‡å¯¹æ¯”
    ax2 = axes[0, 1]
    ax2.plot(thresholds, edge_accs, 'g-o', label='Edge Accuracy', linewidth=2, markersize=8)
    ax2.plot(thresholds, cloud_accs, 'm-s', label='Cloud Accuracy', linewidth=2, markersize=8)
    ax2.plot(thresholds, accuracies, 'b-^', label='Overall Accuracy', linewidth=2, markersize=8)
    ax2.set_xlabel('Confidence Threshold T', fontsize=12)
    ax2.set_ylabel('Accuracy (%)', fontsize=12)
    ax2.legend(fontsize=10)
    ax2.grid(True, alpha=0.3)
    ax2.set_title('Edge vs Cloud Accuracy', fontsize=14, fontweight='bold')
    
    # 3. å»¶è¿Ÿåˆ†æ
    ax3 = axes[1, 0]
    ax3.plot(thresholds, avg_times, 'purple', marker='o', linewidth=2, markersize=8, label='Average Total Time')
    ax3.set_xlabel('Confidence Threshold T', fontsize=12)
    ax3.set_ylabel('Average Time (ms)', fontsize=12)
    ax3.legend(fontsize=10)
    ax3.grid(True, alpha=0.3)
    ax3.set_title('Average Inference Time', fontsize=14, fontweight='bold')
    
    # 4. å‡†ç¡®ç‡ vs äº‘ç«¯è°ƒç”¨ç‡ï¼ˆæ•£ç‚¹å›¾ï¼‰
    ax4 = axes[1, 1]
    scatter = ax4.scatter(cloud_ratios, accuracies, c=thresholds, cmap='viridis', 
                         s=100, alpha=0.6, edgecolors='black', linewidth=1.5)
    ax4.set_xlabel('Cloud Offloading Ratio', fontsize=12)
    ax4.set_ylabel('Overall Accuracy (%)', fontsize=12)
    ax4.grid(True, alpha=0.3)
    ax4.set_title('Accuracy vs Cloud Ratio (Trade-off)', fontsize=14, fontweight='bold')
    cbar = plt.colorbar(scatter, ax=ax4)
    cbar.set_label('Threshold T', fontsize=10)
    
    plt.tight_layout()
    os.makedirs(save_path, exist_ok=True)
    plt.savefig(os.path.join(save_path, 'edge_cloud_collaborative_results.png'), 
                dpi=300, bbox_inches='tight')
    print(f"å®éªŒç»“æœå›¾è¡¨å·²ä¿å­˜åˆ°: {os.path.join(save_path, 'edge_cloud_collaborative_results.png')}")
    plt.close()


def main():
    """
    è¾¹-äº‘ååŒæ¨ç†ç³»ç»Ÿä¸»å‡½æ•°
    å¯ä»¥ç›´æ¥è¿è¡Œæ­¤è„šæœ¬è¿›è¡ŒååŒæ¨ç†å®éªŒ
    """
    import argparse
    import sys
    import os
    import json
    import platform
    from torch.utils.data import DataLoader
    import importlib
    
    # å¯¼å…¥ project æ¡†æ¶çš„æ¨¡å‹åˆ›å»ºå‡½æ•°
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    from project import create_model_by_type

    # å…¼å®¹æ—§checkpointï¼šå†å²ä¸Šæ¨¡å‹ä¿å­˜æ—¶å¯èƒ½pickleäº†æ—§æ¨¡å—è·¯å¾„ï¼ˆå¦‚ readdata_rml2016ï¼‰
    # ä½†å½“å‰é¡¹ç›®å·²å°†æ•°æ®åŠ è½½å™¨ç§»åˆ° utils/ ä¸‹ï¼Œä¼šå¯¼è‡´ torch.load ååºåˆ—åŒ–å¤±è´¥ã€‚
    # è¿™é‡Œé€šè¿‡ sys.modules æ³¨å†Œåˆ«åï¼Œè®© unpickler èƒ½æ‰¾åˆ°å¯¹åº”æ¨¡å—ã€‚
    legacy_to_new = {
        'readdata_25': 'utils.readdata_25',
        'readdata_radioml': 'utils.readdata_radioml',
        'readdata_reii': 'utils.readdata_reii',
        'readdata_radar': 'utils.readdata_radar',
        'readdata_rml2016': 'utils.readdata_rml2016',
        'readdata_link11': 'utils.readdata_link11',
    }
    for legacy_name, new_name in legacy_to_new.items():
        if legacy_name in sys.modules:
            continue
        try:
            sys.modules[legacy_name] = importlib.import_module(new_name)
        except ImportError:
            # å¦‚æœ utils ä¸‹ä¹Ÿä¸å­˜åœ¨å¯¹åº”æ¨¡å—ï¼Œå°±ä¸æ³¨å†Œåˆ«å
            pass
    
    parser = argparse.ArgumentParser(description='è¾¹-äº‘ååŒæ¨ç†ç³»ç»Ÿå®éªŒï¼ˆé€‚é… project æ¡†æ¶ï¼‰')
    
    # æ•°æ®é›†ç±»å‹
    parser.add_argument('--dataset_type', type=str, default='ads',
                        choices=['ads', 'radioml', 'reii', 'radar', 'rml2016', 'link11'],
                        help='æ•°æ®é›†ç±»å‹ (default: ads)')
    
    # æ¨¡å‹è·¯å¾„
    parser.add_argument('--edge_model_path', type=str, default='',
                        help='è¾¹ä¾§æ¨¡å‹è·¯å¾„ï¼ˆreal_resnet20å­¦ç”Ÿæ¨¡å‹ï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ï¼‰')
    parser.add_argument('--cloud_model_path', type=str, default='',
                        help='äº‘ä¾§æ¨¡å‹è·¯å¾„ï¼ˆcomplex_resnet50æ•™å¸ˆæ¨¡å‹ï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ï¼‰')
    
    # æ•°æ®é›†è·¯å¾„ï¼ˆæ ¹æ®æ•°æ®é›†ç±»å‹è®¾ç½®é»˜è®¤è·¯å¾„ï¼‰
    parser.add_argument('--data_path', type=str, default='',
                        help='æ•°æ®é›†è·¯å¾„ï¼ˆæ ¹æ®dataset_typeè‡ªåŠ¨è®¾ç½®ï¼Œä¹Ÿå¯æ‰‹åŠ¨æŒ‡å®šï¼‰')
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument('--num_classes', type=int, default=None,
                        help='ç±»åˆ«æ•°é‡ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œä¼šæ ¹æ®æ•°æ®é›†è‡ªåŠ¨ç¡®å®šï¼‰')
    parser.add_argument('--batch_size', type=int, default=32,
                        help='æ‰¹æ¬¡å¤§å° (default: 32)')
    parser.add_argument('--num_workers', type=int, default=0,
                        help='æ•°æ®åŠ è½½å™¨å·¥ä½œçº¿ç¨‹æ•° (default: 0ï¼ŒWindowså»ºè®®ä½¿ç”¨0)')
    
    # SNRè¿‡æ»¤ï¼ˆä»…å¯¹radiomlå’Œrml2016æœ‰æ•ˆï¼‰
    def parse_snr_value(value):
        """è§£æSNRå€¼ï¼Œæ”¯æŒNoneå­—ç¬¦ä¸²"""
        if value is None or value == 'None' or value == 'none' or value == '':
            return None
        try:
            return int(value)
        except ValueError:
            return None
    
    parser.add_argument('--radioml_snr_min', type=str, default=None,
                        help='RadioML/RML2016æœ€å°SNRé˜ˆå€¼ï¼ˆdBï¼‰ï¼ŒNoneæˆ–ä¸æŒ‡å®šè¡¨ç¤ºä¸è¿‡æ»¤ã€‚æ³¨æ„ï¼šå¦‚æœè®­ç»ƒæ—¶ä½¿ç”¨äº†SNRè¿‡æ»¤ï¼Œè¯„ä¼°æ—¶ä¹Ÿåº”ä½¿ç”¨ç›¸åŒçš„è¿‡æ»¤')
    parser.add_argument('--radioml_snr_max', type=str, default=None,
                        help='RadioML/RML2016æœ€å¤§SNRé˜ˆå€¼ï¼ˆdBï¼‰ï¼ŒNoneæˆ–ä¸æŒ‡å®šè¡¨ç¤ºä¸è¿‡æ»¤ã€‚æ³¨æ„ï¼šå¦‚æœè®­ç»ƒæ—¶ä½¿ç”¨äº†SNRè¿‡æ»¤ï¼Œè¯„ä¼°æ—¶ä¹Ÿåº”ä½¿ç”¨ç›¸åŒçš„è¿‡æ»¤')
    
    # è‡ªåŠ¨ä»è®­ç»ƒç»“æœç›®å½•è¯»å–é…ç½®ï¼ˆå¦‚æœæ¨¡å‹è·¯å¾„åœ¨resultç›®å½•ä¸‹ï¼‰
    parser.add_argument('--auto_load_config', action='store_true', default=True,
                        help='è‡ªåŠ¨ä»è®­ç»ƒç»“æœç›®å½•çš„config.jsonè¯»å–SNRè¿‡æ»¤ç­‰å‚æ•°ï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    
    # å®éªŒå‚æ•°
    parser.add_argument('--thresholds', type=str, default='0.5,0.6,0.7,0.8,0.9',
                        help='ç½®ä¿¡åº¦é˜ˆå€¼åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆä¾‹å¦‚ï¼š0.5,0.7,0.9ï¼‰')
    parser.add_argument('--num_batches', type=int, default=None,
                        help='è¯„ä¼°çš„æ‰¹æ¬¡æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼Œå¦‚éœ€å¿«é€Ÿæµ‹è¯•å¯è®¾ç½®ä¸º50ï¼‰')
    
    # ç½‘ç»œå‚æ•°ï¼ˆæ¨¡æ‹Ÿï¼‰
    parser.add_argument('--cloud_latency_ms', type=float, default=50.0,
                        help='äº‘ç«¯æ¨ç†å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ (default: 50.0)')
    parser.add_argument('--bandwidth_mbps', type=float, default=100.0,
                        help='å¸¦å®½ï¼ˆMbpsï¼‰ (default: 100.0)')
    parser.add_argument('--image_size_mb', type=float, default=0.1,
                        help='å›¾åƒå¤§å°ï¼ˆMBï¼‰ (default: 0.1)')
    
    # ä¿å­˜è·¯å¾„
    parser.add_argument('--save_path', type=str, default='result_edge_cloud_collaborative',
                        help='ç»“æœä¿å­˜è·¯å¾„ (default: result_edge_cloud_collaborative)')
    
    args = parser.parse_args()
    
    # è‡ªåŠ¨ä»è®­ç»ƒç»“æœç›®å½•è¯»å–é…ç½®ï¼ˆå¦‚æœæ¨¡å‹è·¯å¾„åœ¨resultç›®å½•ä¸‹ï¼‰
    if args.auto_load_config and args.edge_model_path:
        # å°è¯•ä»æ¨¡å‹è·¯å¾„æ¨æ–­è®­ç»ƒç»“æœç›®å½•
        edge_model_dir = os.path.dirname(os.path.abspath(args.edge_model_path))
        # å¦‚æœè·¯å¾„åŒ…å« kd_trained_modelsï¼Œåˆ™ä¸Šä¸€çº§ç›®å½•æ˜¯ç»“æœç›®å½•
        if 'kd_trained_models' in edge_model_dir:
            result_dir = os.path.dirname(edge_model_dir)
            config_path = os.path.join(result_dir, 'config.json')
            
            if os.path.exists(config_path):
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        train_config = json.load(f)
                    
                    print(f"\n[INFO] ä»è®­ç»ƒé…ç½®åŠ è½½å‚æ•°: {config_path}")
                    
                    # è¯»å–SNRè¿‡æ»¤å‚æ•°ï¼ˆä½†éœ€è¦éªŒè¯æ•°æ®é›†ä¸­æ˜¯å¦æœ‰è¯¥èŒƒå›´çš„SNRï¼‰
                    # æ³¨æ„ï¼šå¦‚æœè®­ç»ƒé…ç½®ä¸­çš„SNRèŒƒå›´ä¸æ•°æ®é›†ä¸åŒ¹é…ï¼Œä¼šå¯¼è‡´æµ‹è¯•é›†ä¸ºç©º
                    if args.radioml_snr_min is None and 'radioml_snr_min' in train_config:
                        config_snr_min = train_config['radioml_snr_min']
                        # å…ˆä¸è‡ªåŠ¨è®¾ç½®ï¼Œå› ä¸ºå¯èƒ½ä¸åŒ¹é…
                        print(f"   è®­ç»ƒé…ç½®ä¸­çš„SNRèŒƒå›´: [{config_snr_min}, {train_config.get('radioml_snr_max', 'N/A')}] dB")
                        print(f"   [WARNING] æ³¨æ„ï¼šå¦‚æœæ•°æ®é›†ä¸­æ²¡æœ‰è¯¥SNRèŒƒå›´çš„æ•°æ®ï¼Œæµ‹è¯•é›†å°†ä¸ºç©º")
                        print(f"   å»ºè®®ï¼šå…ˆä¸ä½¿ç”¨SNRè¿‡æ»¤è¿›è¡Œè¯„ä¼°ï¼Œæˆ–æ£€æŸ¥æ•°æ®é›†çš„å®é™…SNRèŒƒå›´")
                        # æš‚æ—¶ä¸è‡ªåŠ¨è®¾ç½®ï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨å†³å®š
                        # args.radioml_snr_min = config_snr_min
                    
                    if args.radioml_snr_max is None and 'radioml_snr_max' in train_config:
                        config_snr_max = train_config['radioml_snr_max']
                        # æš‚æ—¶ä¸è‡ªåŠ¨è®¾ç½®
                        # args.radioml_snr_max = config_snr_max
                    
                    # æ³¨æ„ï¼šè®­ç»ƒæ—¶å¯èƒ½ä½¿ç”¨äº†å™ªå£°ï¼Œä½†è¯„ä¼°æ—¶é€šå¸¸ä¸åŠ å™ªå£°
                    # å¦‚æœéœ€è¦å®Œå…¨ä¸€è‡´ï¼Œå¯ä»¥æ·»åŠ  --use_training_noise å‚æ•°
                    if 'add_noise' in train_config and train_config['add_noise']:
                        print(f"   [WARNING] è®­ç»ƒæ—¶ä½¿ç”¨äº†å™ªå£° (type={train_config.get('noise_type', 'unknown')}, factor={train_config.get('noise_factor', 'unknown')})")
                        print(f"   è¯„ä¼°æ—¶é»˜è®¤ä¸åŠ å™ªå£°ï¼Œå¦‚éœ€ä¸€è‡´è¯·æ‰‹åŠ¨è®¾ç½®")
                    
                except Exception as e:
                    print(f"   [WARNING] è¯»å–è®­ç»ƒé…ç½®å¤±è´¥: {e}")
    
    # è®¾ç½®é»˜è®¤æ•°æ®é›†è·¯å¾„ï¼ˆæ ¹æ®æ•°æ®é›†ç±»å‹ï¼‰
    if not args.data_path:
        default_paths = {
            'ads': r'E:\ADS-B_6000_100class\\',
            'radioml': r'E:\BaiduNet_Download\augmented_data.pkl',
            'reii': r'E:\BaiduNet_Download\REII\\',
            'radar': r'E:\BaiduNet_Download\Radar Emitter Individual Identification\Radar Emitter Individual Identification\dataGen\RadarDataset_20251124_144839_161000samples_Repeat1.mat',
            'rml2016': r'E:\BaiduNet_Download\rml2016.pkl',
            'link11': r'E:\BaiduNet_Download\link11.pkl'
        }
        args.data_path = default_paths.get(args.dataset_type, '')
        if not args.data_path:
            print(f"é”™è¯¯: æ•°æ®é›†ç±»å‹ {args.dataset_type} æ²¡æœ‰é»˜è®¤è·¯å¾„ï¼Œè¯·ä½¿ç”¨ --data_path æŒ‡å®š")
            return
    
    # è®¾ç½®é»˜è®¤ç±»åˆ«æ•°ï¼ˆæ ¹æ®æ•°æ®é›†ç±»å‹ï¼‰
    if args.num_classes is None:
        class_map = {
            'ads': 100,
            'radioml': 11,
            'reii': 3,
            'radar': 7,
            'rml2016': 6,
            'link11': 7
        }
        args.num_classes = class_map.get(args.dataset_type, 10)
    
    # æ£€æŸ¥å¿…éœ€å‚æ•°
    if not args.edge_model_path:
        print("é”™è¯¯: è¯·æä¾› --edge_model_path å‚æ•°ï¼ˆè¾¹ä¾§æ¨¡å‹è·¯å¾„ï¼‰")
        print("ç¤ºä¾‹: --edge_model_path ./result/xxx/kd_trained_models/client_001_kd_model.pth")
        return
    
    if not args.cloud_model_path:
        print("é”™è¯¯: è¯·æä¾› --cloud_model_path å‚æ•°ï¼ˆäº‘ä¾§æ¨¡å‹è·¯å¾„ï¼‰")
        print("ç¤ºä¾‹: --cloud_model_path ./result/xxx/pretrained_server_model.pth")
        return
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_path, exist_ok=True)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"\n{'='*80}")
    print(f"[CONFIG] è¾¹-äº‘ååŒæ¨ç†ç³»ç»Ÿé…ç½®ï¼ˆé€‚é… project æ¡†æ¶ï¼‰")
    print(f"{'='*80}")
    print(f"[INFO] æ•°æ®é›†ç±»å‹: {args.dataset_type}")
    print(f"[INFO] æ•°æ®é›†è·¯å¾„: {args.data_path}")
    print(f"[INFO] è¾¹ä¾§æ¨¡å‹: {args.edge_model_path}")
    print(f"   æ¨¡å‹ç±»å‹: real_resnet20_{args.dataset_type}")
    print(f"[INFO] äº‘ä¾§æ¨¡å‹: {args.cloud_model_path}")
    print(f"   æ¨¡å‹ç±»å‹: complex_resnet50_{args.dataset_type}")
    print(f"[INFO] ç±»åˆ«æ•°: {args.num_classes}")
    print(f"[INFO] æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    # è§£æSNRå‚æ•°ç”¨äºæ˜¾ç¤º
    def parse_snr_display(value):
        if value is None or value == 'None' or value == 'none' or value == '':
            return None
        try:
            return int(value)
        except (ValueError, TypeError):
            return None
    snr_min_display = parse_snr_display(args.radioml_snr_min)
    snr_max_display = parse_snr_display(args.radioml_snr_max)
    if snr_min_display is not None and snr_max_display is not None:
        print(f"[INFO] SNRè¿‡æ»¤: [{snr_min_display}, {snr_max_display}] dB")
    else:
        print(f"[INFO] SNRè¿‡æ»¤: æ— ï¼ˆä½¿ç”¨æ‰€æœ‰SNRèŒƒå›´ï¼‰")
    print(f"{'='*80}\n")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®é›†
    print(f"\n{'='*80}")
    print(f"[DATA] åŠ è½½æ•°æ®é›†")
    print(f"{'='*80}")
    
    # è§£æSNRè¿‡æ»¤å‚æ•°
    def parse_snr_value(value):
        """è§£æSNRå€¼ï¼Œæ”¯æŒNoneå­—ç¬¦ä¸²"""
        if value is None or value == 'None' or value == 'none' or value == '':
            return None
        try:
            return int(value)
        except (ValueError, TypeError):
            return None
    
    snr_min = parse_snr_value(args.radioml_snr_min)
    snr_max = parse_snr_value(args.radioml_snr_max)
    
    snr_filter = None
    if snr_min is not None and snr_max is not None:
        snr_filter = (snr_min, snr_max)
        print(f"   ä½¿ç”¨SNRè¿‡æ»¤: [{snr_min}, {snr_max}] dB")
    else:
        print(f"   ä¸ä½¿ç”¨SNRè¿‡æ»¤ï¼ˆä½¿ç”¨æ‰€æœ‰SNRèŒƒå›´çš„æ•°æ®ï¼‰")
    
    try:
        if args.dataset_type == 'radioml':
            try:
                from utils.readdata_radioml import RadioMLDataset
            except ImportError:
                from readdata_radioml import RadioMLDataset
            test_dataset = RadioMLDataset(datapath=args.data_path, split='test', 
                                         transform=None, snr_filter=snr_filter)
        elif args.dataset_type == 'rml2016':
            try:
                from utils.readdata_rml2016 import RML2016Dataset
            except ImportError:
                from readdata_rml2016 import RML2016Dataset
            # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒé…ç½®æ–‡ä»¶ï¼Œå¦‚æœæœ‰åˆ™ä½¿ç”¨ç›¸åŒçš„å‚æ•°
            # é»˜è®¤ä¸ä½¿ç”¨SNRè¿‡æ»¤å’Œå™ªå£°ï¼ˆä¸è®­ç»ƒæ—¶å¯èƒ½ä¸ä¸€è‡´ï¼Œä½†æ›´é€šç”¨ï¼‰
            # å¦‚æœéœ€è¦ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼Œéœ€è¦ä»config.jsonè¯»å–å‚æ•°
            test_dataset = RML2016Dataset(
                pkl_path=args.data_path, 
                split='test',
                snr_range=snr_filter,  # å¦‚æœæä¾›äº†SNRè¿‡æ»¤å‚æ•°åˆ™ä½¿ç”¨
                seed=42,
                add_noise=False,  # è¯„ä¼°æ—¶é»˜è®¤ä¸åŠ å™ªå£°
                noise_type='awgn',
                noise_snr_db=15,
                noise_factor=0.1
            )
        elif args.dataset_type == 'link11':
            try:
                from utils.readdata_link11 import Link11Dataset
            except ImportError:
                from readdata_link11 import Link11Dataset
            test_dataset = Link11Dataset(pkl_path=args.data_path, split='test',
                                        snr_range=snr_filter, seed=42)
        elif args.dataset_type == 'reii':
            try:
                from utils.readdata_reii import REIIDataset
            except ImportError:
                from readdata_reii import REIIDataset
            test_dataset = REIIDataset(datapath=args.data_path, split='test', transform=None)
        elif args.dataset_type == 'radar':
            try:
                from utils.readdata_radar import RadarDataset
            except ImportError:
                from readdata_radar import RadarDataset
            test_dataset = RadarDataset(mat_path=args.data_path, split='test', transform=None)
        else:  # ads æˆ–å…¶ä»–
            try:
                from utils.readdata_25 import subDataset
            except ImportError:
                from readdata_25 import subDataset
            test_dataset = subDataset(datapath=args.data_path, split='test', 
                                    transform=None, allowed_classes=None)
        
        # è·å–å®é™…ç±»åˆ«æ•°ï¼ˆå¦‚æœæ•°æ®é›†æœ‰å±æ€§ï¼‰
        if hasattr(test_dataset, 'num_classes'):
            actual_num_classes = test_dataset.num_classes
            if actual_num_classes != args.num_classes:
                print(f"[WARNING] è­¦å‘Š: æ•°æ®é›†å®é™…ç±»åˆ«æ•° ({actual_num_classes}) ä¸æŒ‡å®šç±»åˆ«æ•° ({args.num_classes}) ä¸ç¬¦")
                print(f"   ä½¿ç”¨æ•°æ®é›†å®é™…ç±»åˆ«æ•°: {actual_num_classes}")
                args.num_classes = actual_num_classes
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        num_workers = args.num_workers
        if platform.system() == 'Windows' and num_workers > 0:
            num_workers = 0
            print(f"[WARNING] Windowsç³»ç»Ÿè‡ªåŠ¨è®¾ç½® num_workers=0 é¿å…å¤šè¿›ç¨‹é—®é¢˜")
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=torch.cuda.is_available()
        )
        
        print(f"[SUCCESS] æµ‹è¯•é›†åŠ è½½æˆåŠŸ: {len(test_dataset):,} æ ·æœ¬")
        
        # æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦ä¸ºç©º
        if len(test_dataset) == 0:
            print(f"\n[ERROR] é”™è¯¯: æµ‹è¯•é›†ä¸ºç©ºï¼")
            if args.dataset_type in ['rml2016', 'radioml'] and (args.radioml_snr_min is not None or args.radioml_snr_max is not None):
                print(f"   å¯èƒ½åŸå› : SNRè¿‡æ»¤èŒƒå›´ [{args.radioml_snr_min}, {args.radioml_snr_max}] ä¸æ•°æ®é›†ä¸åŒ¹é…")
                print(f"   è§£å†³æ–¹æ¡ˆ: ç§»é™¤SNRè¿‡æ»¤ï¼Œä½¿ç”¨æ‰€æœ‰æ•°æ®")
                print(f"   å‘½ä»¤: æ·»åŠ  --radioml_snr_min None --radioml_snr_max None")
                print(f"   æˆ–è€…: ä¸æŒ‡å®šSNRå‚æ•°ï¼Œä½¿ç”¨æ‰€æœ‰SNRèŒƒå›´çš„æ•°æ®")
            return
        
    except Exception as e:
        print(f"[ERROR] æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åŠ è½½è¾¹ä¾§æ¨¡å‹ï¼ˆreal_resnet20ï¼‰
    print(f"\n{'='*80}")
    print(f"ğŸ“¦ åŠ è½½è¾¹ä¾§æ¨¡å‹ï¼ˆreal_resnet20ï¼‰")
    print(f"{'='*80}")
    
    try:
        edge_model_name = f'real_resnet20_{args.dataset_type}' if args.dataset_type != 'ads' else 'real_resnet20_ads'
        edge_model = create_model_by_type(edge_model_name, args.num_classes, args.dataset_type)
        edge_model = edge_model.to(device)
        
        # åŠ è½½æƒé‡
        if not os.path.exists(args.edge_model_path):
            print(f"[ERROR] é”™è¯¯: è¾¹ä¾§æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.edge_model_path}")
            return
        
        edge_checkpoint = torch.load(args.edge_model_path, map_location=device, weights_only=False)
        
        # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
        state_dict_to_load = None
        if isinstance(edge_checkpoint, dict):
            if 'model_state_dict' in edge_checkpoint:
                state_dict_to_load = edge_checkpoint['model_state_dict']
                print(f"   æ£€æµ‹åˆ°checkpointæ ¼å¼ï¼ˆåŒ…å«'model_state_dict'é”®ï¼‰")
            elif 'state_dict' in edge_checkpoint:
                state_dict_to_load = edge_checkpoint['state_dict']
                print(f"   æ£€æµ‹åˆ°checkpointæ ¼å¼ï¼ˆåŒ…å«'state_dict'é”®ï¼‰")
            else:
                # å¯èƒ½æ˜¯ç›´æ¥ä¿å­˜çš„state_dict
                state_dict_to_load = edge_checkpoint
                print(f"   æ£€æµ‹åˆ°ç›´æ¥ä¿å­˜çš„state_dictæ ¼å¼")
        else:
            state_dict_to_load = edge_checkpoint
            print(f"   æ£€æµ‹åˆ°ç›´æ¥ä¿å­˜çš„state_dictæ ¼å¼")
        
        # åŠ è½½æƒé‡å¹¶æ£€æŸ¥åŒ¹é…æƒ…å†µ
        missing_keys, unexpected_keys = edge_model.load_state_dict(state_dict_to_load, strict=False)
        
        if missing_keys:
            print(f"[WARNING] è­¦å‘Š: ä»¥ä¸‹é”®æœªåŠ è½½ï¼ˆ{len(missing_keys)}ä¸ªï¼‰:")
            if len(missing_keys) <= 10:
                for key in missing_keys:
                    print(f"     - {key}")
            else:
                for key in missing_keys[:5]:
                    print(f"     - {key}")
                print(f"     ... è¿˜æœ‰ {len(missing_keys)-5} ä¸ªé”®æœªæ˜¾ç¤º")
        
        if unexpected_keys:
            print(f"[WARNING] è­¦å‘Š: ä»¥ä¸‹é”®åœ¨checkpointä¸­ä½†ä¸åœ¨æ¨¡å‹ä¸­ï¼ˆ{len(unexpected_keys)}ä¸ªï¼‰:")
            if len(unexpected_keys) <= 10:
                for key in unexpected_keys:
                    print(f"     - {key}")
            else:
                for key in unexpected_keys[:5]:
                    print(f"     - {key}")
                print(f"     ... è¿˜æœ‰ {len(unexpected_keys)-5} ä¸ªé”®æœªæ˜¾ç¤º")
        
        if not missing_keys and not unexpected_keys:
            print(f"   [SUCCESS] æ‰€æœ‰æƒé‡å®Œç¾åŒ¹é…")
        elif len(missing_keys) > len(state_dict_to_load) * 0.5:
            print(f"   [WARNING] ä¸¥é‡è­¦å‘Š: è¶…è¿‡50%çš„æƒé‡æœªåŠ è½½ï¼Œæ¨¡å‹å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œï¼")
        
        print(f"[SUCCESS] è¾¹ä¾§æ¨¡å‹åŠ è½½å®Œæˆ")
        
    except Exception as e:
        print(f"[ERROR] è¾¹ä¾§æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åŠ è½½äº‘ä¾§æ¨¡å‹ï¼ˆcomplex_resnet50ï¼‰
    print(f"\n{'='*80}")
    print(f"ğŸ“¦ åŠ è½½äº‘ä¾§æ¨¡å‹ï¼ˆcomplex_resnet50ï¼‰")
    print(f"{'='*80}")
    
    try:
        cloud_model_name = f'complex_resnet50_{args.dataset_type}' if args.dataset_type != 'ads' else 'complex_resnet50_ads'
        cloud_model = create_model_by_type(cloud_model_name, args.num_classes, args.dataset_type)
        cloud_model = cloud_model.to(device)
        
        # åŠ è½½æƒé‡
        if not os.path.exists(args.cloud_model_path):
            print(f"[ERROR] é”™è¯¯: äº‘ä¾§æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.cloud_model_path}")
            return
        
        cloud_checkpoint = torch.load(args.cloud_model_path, map_location=device, weights_only=False)
        
        # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
        state_dict_to_load = None
        if isinstance(cloud_checkpoint, dict):
            if 'model_state_dict' in cloud_checkpoint:
                state_dict_to_load = cloud_checkpoint['model_state_dict']
                print(f"   æ£€æµ‹åˆ°checkpointæ ¼å¼ï¼ˆåŒ…å«'model_state_dict'é”®ï¼‰")
            elif 'state_dict' in cloud_checkpoint:
                state_dict_to_load = cloud_checkpoint['state_dict']
                print(f"   æ£€æµ‹åˆ°checkpointæ ¼å¼ï¼ˆåŒ…å«'state_dict'é”®ï¼‰")
            else:
                # å¯èƒ½æ˜¯ç›´æ¥ä¿å­˜çš„state_dict
                state_dict_to_load = cloud_checkpoint
                print(f"   æ£€æµ‹åˆ°ç›´æ¥ä¿å­˜çš„state_dictæ ¼å¼")
        else:
            state_dict_to_load = cloud_checkpoint
            print(f"   æ£€æµ‹åˆ°ç›´æ¥ä¿å­˜çš„state_dictæ ¼å¼")
        
        # åŠ è½½æƒé‡å¹¶æ£€æŸ¥åŒ¹é…æƒ…å†µ
        missing_keys, unexpected_keys = cloud_model.load_state_dict(state_dict_to_load, strict=False)
        
        if missing_keys:
            print(f"[WARNING] è­¦å‘Š: ä»¥ä¸‹é”®æœªåŠ è½½ï¼ˆ{len(missing_keys)}ä¸ªï¼‰:")
            if len(missing_keys) <= 10:
                for key in missing_keys:
                    print(f"     - {key}")
            else:
                for key in missing_keys[:5]:
                    print(f"     - {key}")
                print(f"     ... è¿˜æœ‰ {len(missing_keys)-5} ä¸ªé”®æœªæ˜¾ç¤º")
        
        if unexpected_keys:
            print(f"[WARNING] è­¦å‘Š: ä»¥ä¸‹é”®åœ¨checkpointä¸­ä½†ä¸åœ¨æ¨¡å‹ä¸­ï¼ˆ{len(unexpected_keys)}ä¸ªï¼‰:")
            if len(unexpected_keys) <= 10:
                for key in unexpected_keys:
                    print(f"     - {key}")
            else:
                for key in unexpected_keys[:5]:
                    print(f"     - {key}")
                print(f"     ... è¿˜æœ‰ {len(unexpected_keys)-5} ä¸ªé”®æœªæ˜¾ç¤º")
        
        if not missing_keys and not unexpected_keys:
            print(f"   [SUCCESS] æ‰€æœ‰æƒé‡å®Œç¾åŒ¹é…")
        elif len(missing_keys) > len(state_dict_to_load) * 0.5:
            print(f"   [WARNING] ä¸¥é‡è­¦å‘Š: è¶…è¿‡50%çš„æƒé‡æœªåŠ è½½ï¼Œæ¨¡å‹å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œï¼")
        
        print(f"[SUCCESS] äº‘ä¾§æ¨¡å‹åŠ è½½å®Œæˆ")
        
    except Exception as e:
        print(f"[ERROR] äº‘ä¾§æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è¯„ä¼°è¾¹ä¾§å’Œäº‘ä¾§æ¨¡å‹å•ç‹¬æ€§èƒ½
    print(f"\n{'='*80}")
    print(f"[EVAL] è¯„ä¼°æ¨¡å‹å•ç‹¬æ€§èƒ½")
    print(f"{'='*80}")
    
    # è¯„ä¼°è¾¹ä¾§æ¨¡å‹ï¼ˆä½¿ç”¨ä¸è®­ç»ƒä»£ç ç›¸åŒçš„è¯„ä¼°æ–¹å¼ï¼‰
    print("\nè¯„ä¼°è¾¹ä¾§æ¨¡å‹...")
    edge_model.eval()
    edge_correct = 0
    edge_total = 0
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="è¾¹ä¾§æ¨¡å‹è¯„ä¼°"):
            # å¤„ç†batchæ ¼å¼ï¼ˆå…¼å®¹ä¸åŒæ•°æ®é›†çš„è¿”å›æ ¼å¼ï¼‰
            if len(batch) == 3:
                inputs, targets, _ = batch
            elif len(batch) == 2:
                inputs, targets = batch
            else:
                continue
            
            inputs = inputs.to(device)
            targets = targets.to(device)
            
            # RML2016æ•°æ®é›†ï¼šè¾“å…¥å·²ç»æ˜¯ (batch_size, 600) å¤æ•°ï¼Œç›´æ¥ä½¿ç”¨
            # å…¶ä»–æ•°æ®é›†å¯èƒ½éœ€è¦è½¬æ¢ï¼Œä½†RML2016ä¸éœ€è¦é¢å¤–å¤„ç†
            if args.dataset_type == 'rml2016':
                # RML2016: è¾“å…¥å·²ç»æ˜¯å¤æ•°æ ¼å¼ (batch_size, 600)ï¼Œç›´æ¥ä¼ ç»™æ¨¡å‹
                # æ¨¡å‹çš„forwardæ–¹æ³•ä¼šè‡ªå·±å¤„ç†
                outputs = edge_model(inputs)
            else:
                # å…¶ä»–æ•°æ®é›†ï¼šç¡®ä¿è¾“å…¥æ˜¯å¤æ•°æ ¼å¼
                if not torch.is_complex(inputs):
                    if inputs.dim() == 2:
                        inputs_real = inputs
                        inputs_imag = torch.zeros_like(inputs_real)
                        inputs = torch.view_as_complex(torch.stack([inputs_real, inputs_imag], dim=-1))
                outputs = edge_model(inputs)
            
            # å¤„ç†è¾“å‡ºï¼ˆæ¨¡å‹å¯èƒ½è¿”å›å¤æ•°ï¼Œéœ€è¦å–æ¨¡ï¼‰
            if torch.is_complex(outputs):
                outputs = torch.abs(outputs)
            
            # è®¡ç®—å‡†ç¡®ç‡ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
            _, predicted = outputs.max(1)
            edge_total += targets.size(0)
            edge_correct += predicted.eq(targets).sum().item()
    
    edge_alone_acc = 100. * edge_correct / edge_total if edge_total > 0 else 0
    print(f"è¾¹ä¾§æ¨¡å‹å‡†ç¡®ç‡: {edge_alone_acc:.2f}% ({edge_correct}/{edge_total})")
    
    # è¯„ä¼°äº‘ä¾§æ¨¡å‹ï¼ˆä½¿ç”¨ä¸è®­ç»ƒä»£ç ç›¸åŒçš„è¯„ä¼°æ–¹å¼ï¼‰
    print("\nè¯„ä¼°äº‘ä¾§æ¨¡å‹...")
    cloud_model.eval()
    cloud_correct = 0
    cloud_total = 0
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="äº‘ä¾§æ¨¡å‹è¯„ä¼°"):
            # å¤„ç†batchæ ¼å¼ï¼ˆå…¼å®¹ä¸åŒæ•°æ®é›†çš„è¿”å›æ ¼å¼ï¼‰
            if len(batch) == 3:
                inputs, targets, _ = batch
            elif len(batch) == 2:
                inputs, targets = batch
            else:
                continue
            
            inputs = inputs.to(device)
            targets = targets.to(device)
            
            # RML2016æ•°æ®é›†ï¼šè¾“å…¥å·²ç»æ˜¯ (batch_size, 600) å¤æ•°ï¼Œç›´æ¥ä½¿ç”¨
            # å…¶ä»–æ•°æ®é›†å¯èƒ½éœ€è¦è½¬æ¢ï¼Œä½†RML2016ä¸éœ€è¦é¢å¤–å¤„ç†
            if args.dataset_type == 'rml2016':
                # RML2016: è¾“å…¥å·²ç»æ˜¯å¤æ•°æ ¼å¼ (batch_size, 600)ï¼Œç›´æ¥ä¼ ç»™æ¨¡å‹
                # æ¨¡å‹çš„forwardæ–¹æ³•ä¼šè‡ªå·±å¤„ç†
                outputs = cloud_model(inputs)
            else:
                # å…¶ä»–æ•°æ®é›†ï¼šç¡®ä¿è¾“å…¥æ˜¯å¤æ•°æ ¼å¼
                if not torch.is_complex(inputs):
                    if inputs.dim() == 2:
                        inputs_real = inputs
                        inputs_imag = torch.zeros_like(inputs_real)
                        inputs = torch.view_as_complex(torch.stack([inputs_real, inputs_imag], dim=-1))
                outputs = cloud_model(inputs)
            
            # å¤„ç†è¾“å‡ºï¼ˆæ¨¡å‹å¯èƒ½è¿”å›å¤æ•°ï¼Œéœ€è¦å–æ¨¡ï¼‰
            if torch.is_complex(outputs):
                outputs = torch.abs(outputs)
            
            # è®¡ç®—å‡†ç¡®ç‡ï¼ˆä¸è®­ç»ƒä»£ç ä¸€è‡´ï¼‰
            _, predicted = outputs.max(1)
            cloud_total += targets.size(0)
            cloud_correct += predicted.eq(targets).sum().item()
    
    cloud_alone_acc = 100. * cloud_correct / cloud_total if cloud_total > 0 else 0
    print(f"äº‘ä¾§æ¨¡å‹å‡†ç¡®ç‡: {cloud_alone_acc:.2f}% ({cloud_correct}/{cloud_total})")
    
    # åˆ›å»ºååŒæ¨ç†ç³»ç»Ÿ
    print(f"\n{'='*80}")
    print(f"[INIT] åˆå§‹åŒ–è¾¹-äº‘ååŒæ¨ç†ç³»ç»Ÿ")
    print(f"{'='*80}")
    
    collaborative_system = EdgeCloudCollaborativeInference(
        edge_model=edge_model,
        cloud_model=cloud_model,
        device=device,
        dataset_type=args.dataset_type,
        cloud_latency_ms=args.cloud_latency_ms,
        bandwidth_mbps=args.bandwidth_mbps,
        image_size_mb=args.image_size_mb
    )
    
    # è§£æé˜ˆå€¼åˆ—è¡¨
    thresholds = [float(t.strip()) for t in args.thresholds.split(',')]
    print(f"\nå°†æµ‹è¯•ä»¥ä¸‹ç½®ä¿¡åº¦é˜ˆå€¼: {thresholds}")
    
    # è¯„ä¼°ä¸åŒé˜ˆå€¼ä¸‹çš„æ€§èƒ½
    print(f"\n{'='*80}")
    print(f"[EXPERIMENT] å¼€å§‹ååŒæ¨ç†å®éªŒ")
    print(f"{'='*80}")
    
    all_results = []
    
    for threshold in thresholds:
        results = collaborative_system.evaluate(
            test_loader,
            threshold=threshold,
            num_batches=args.num_batches
        )
        all_results.append(results)
        
        print(f"\né˜ˆå€¼ T = {threshold:.2f} çš„ç»“æœ:")
        print(f"  æ•´ä½“å‡†ç¡®ç‡: {results['overall_accuracy']:.2f}%")
        print(f"  è¾¹ä¾§å‡†ç¡®ç‡: {results['edge_accuracy']:.2f}%")
        print(f"  äº‘ä¾§å‡†ç¡®ç‡: {results['cloud_accuracy']:.2f}%")
        print(f"  äº‘ç«¯è°ƒç”¨ç‡: {results['cloud_ratio']:.2%}")
        print(f"  å¹³å‡å»¶è¿Ÿ: {results['avg_per_sample_latency_ms']:.4f} ms/æ ·æœ¬")
        if results['speedup_ratio'] > 0:
            print(f"  é€Ÿåº¦æå‡: {results['speedup_ratio']:.2f}x")
    
    # ç»˜åˆ¶ç»“æœ
    print(f"\n{'='*80}")
    print(f"[PLOT] ç»˜åˆ¶å®éªŒç»“æœ")
    print(f"{'='*80}")
    plot_collaborative_results(all_results, args.save_path)
    
    # ä¿å­˜ç»“æœåˆ°JSON
    results_file = os.path.join(args.save_path, 'collaborative_inference_results.json')
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'edge_alone_accuracy': edge_alone_acc,
            'cloud_alone_accuracy': cloud_alone_acc,
            'threshold_results': all_results,
            'experiment_config': {
                'dataset_type': args.dataset_type,
                'data_path': args.data_path,
                'edge_model_path': args.edge_model_path,
                'cloud_model_path': args.cloud_model_path,
                'num_classes': args.num_classes,
                'batch_size': args.batch_size,
                'confidence_thresholds': thresholds,
                'cloud_latency_ms': args.cloud_latency_ms,
                'bandwidth_mbps': args.bandwidth_mbps,
                'image_size_mb': args.image_size_mb
            }
        }, f, indent=2, ensure_ascii=False)
    
    print(f"å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    # æ‰“å°æ€»ç»“
    print(f"\n{'='*80}")
    print(f"[SUMMARY] å®éªŒæ€»ç»“")
    print(f"{'='*80}")
    print(f"è¾¹ä¾§æ¨¡å‹å•ç‹¬å‡†ç¡®ç‡: {edge_alone_acc:.2f}%")
    print(f"äº‘ä¾§æ¨¡å‹å•ç‹¬å‡†ç¡®ç‡: {cloud_alone_acc:.2f}%")
    
    print(f"\nä¸åŒé˜ˆå€¼ä¸‹çš„ååŒæ¨ç†ç»“æœ:")
    print(f"{'é˜ˆå€¼':<8} {'æ•´ä½“å‡†ç¡®ç‡':<12} {'äº‘ç«¯è°ƒç”¨ç‡':<12} {'å¹³å‡å»¶è¿Ÿ(ms)':<15}")
    print("-" * 50)
    for r in all_results:
        print(f"{r['threshold']:<8.2f} {r['overall_accuracy']:<12.2f} {r['cloud_ratio']:<12.2%} {r['avg_per_sample_latency_ms']:<15.4f}")
    
    # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
    if all_results:
        best_result = max(all_results, key=lambda x: x['overall_accuracy'] - 10 * x['cloud_ratio'])
        print(f"\næœ€ä½³é˜ˆå€¼ï¼ˆå¹³è¡¡ç‚¹ï¼‰: T = {best_result['threshold']:.2f}")
        print(f"  æ•´ä½“å‡†ç¡®ç‡: {best_result['overall_accuracy']:.2f}%")
        print(f"  äº‘ç«¯è°ƒç”¨ç‡: {best_result['cloud_ratio']:.2%}")
        
        best_accuracy = max(all_results, key=lambda x: x['overall_accuracy'])
        print(f"\næœ€é«˜å‡†ç¡®ç‡é˜ˆå€¼: T = {best_accuracy['threshold']:.2f}")
        print(f"  æ•´ä½“å‡†ç¡®ç‡: {best_accuracy['overall_accuracy']:.2f}%")
        print(f"  äº‘ç«¯è°ƒç”¨ç‡: {best_accuracy['cloud_ratio']:.2%}")
    
    print(f"\n[SAVE] ç»“æœä¿å­˜è·¯å¾„: {args.save_path}")
    print(f"{'='*80}\n")


if __name__ == '__main__':
    main()
