"""
RadioML æ•°æ®é›†åŠ è½½æ¨¡å—
æ¨¡ä»¿ readdata_25.py çš„ç»“æ„ï¼Œç”¨äºåŠ è½½ pkl æ ¼å¼çš„ RadioML æ•°æ®é›†
"""

import torch
from torch.utils.data import Dataset
import pickle
import numpy as np
import random
import time
import os


# Global cache for loaded data to avoid reloading
_RADIOML_DATA_CACHE = {}


class RadioMLDataset(Dataset):
    """
    RadioML æ•°æ®é›†ç±» (Optimized with caching)
    æ¨¡ä»¿ subDataset çš„ç»“æ„
    
    æ•°æ®æ ¼å¼: {(è°ƒåˆ¶ç±»å‹, SNR): numpyæ•°ç»„(N, 2, 128)}
    """
    
    def __init__(self, datapath, transform, split, snr_filter=None):
        """
        åˆå§‹åŒ– RadioML æ•°æ®é›†
        
        Args:
            datapath: pkl æ–‡ä»¶è·¯å¾„
            transform: æ•°æ®å˜æ¢ï¼ˆä¿æŒæ¥å£ä¸€è‡´ï¼Œå®é™…å¯èƒ½ä¸ç”¨ï¼‰
            split: 'train', 'valid', æˆ– 'test'
            snr_filter: SNR è¿‡æ»¤ï¼Œtuple (min_snr, max_snr) æˆ– None è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰
        """
        self.datapath = datapath
        self.split = split
        self.transform = transform
        self.snr_filter = snr_filter
        
        # åŠ è½½å’Œå¤„ç†æ•°æ® (with caching)
        self._load_and_split_data()
        
    def _load_and_split_data(self):
        """åŠ è½½ pkl æ–‡ä»¶å¹¶åˆ’åˆ†æ•°æ®é›† - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ with caching"""
        
        cache_key = f"{self.datapath}_42"  # seed=42
        
        # Check if data is already in cache
        if cache_key not in _RADIOML_DATA_CACHE:
            load_start_time = time.time()
            print(f"æ­£åœ¨åŠ è½½ RadioML æ•°æ®é›†: {self.datapath}")
            
            pkl_load_start = time.time()
            with open(self.datapath, 'rb') as f:
                raw_data = pickle.load(f)
            pkl_load_time = time.time() - pkl_load_start
            
            # æå–æ‰€æœ‰è°ƒåˆ¶ç±»å‹å¹¶åˆ›å»ºæ ‡ç­¾æ˜ å°„
            extract_start = time.time()
            modulations = sorted(list(set([key[0] for key in raw_data.keys()])))
            modulation_to_label = {mod: idx for idx, mod in enumerate(modulations)}
            num_classes = len(modulations)
            
            print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ (è€—æ—¶: {pkl_load_time:.2f}ç§’)")
            print(f"   è°ƒåˆ¶ç±»å‹: {modulations}")
            print(f"   ç±»åˆ«æ•°: {num_classes}")
            print(f"   æ­£åœ¨åˆ’åˆ†æ•°æ®é›†...")
            
            # æ”¶é›†æ ·æœ¬ç´¢å¼•ï¼ˆä¸å¤åˆ¶æ•°æ®ï¼‰
            sample_indices = []  # å­˜å‚¨ (key, sample_idx) çš„åˆ—è¡¨
            
            for key in raw_data.keys():
                modulation, snr = key
                
                # SNR è¿‡æ»¤
                if self.snr_filter is not None:
                    min_snr, max_snr = self.snr_filter
                    if snr < min_snr or snr > max_snr:
                        continue
                
                num_samples = len(raw_data[key])
                for i in range(num_samples):
                    sample_indices.append((key, i, modulation_to_label[modulation]))
            
            extract_time = time.time() - extract_start
            
            # åˆ’åˆ†ç´¢å¼•
            split_start = time.time()
            random.seed(42)
            random.shuffle(sample_indices)
            
            n_total = len(sample_indices)
            n_train = int(n_total * 0.7)
            n_val = int(n_total * 0.15)
            
            train_indices = sample_indices[:n_train]
            val_indices = sample_indices[n_train:n_train + n_val]
            test_indices = sample_indices[n_train + n_val:]
            split_time = time.time() - split_start
            
            # Cache the data and indices
            _RADIOML_DATA_CACHE[cache_key] = {
                'raw_data': raw_data,
                'modulation_to_label': modulation_to_label,
                'num_classes': num_classes,
                'train_indices': train_indices,
                'val_indices': val_indices,
                'test_indices': test_indices
            }
            
            total_load_time = time.time() - load_start_time
            print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆå¹¶ç¼“å­˜ (è€—æ—¶: {split_time:.2f}ç§’)")
            print(f"   è®­ç»ƒé›†: {len(train_indices)} æ ·æœ¬")
            print(f"   éªŒè¯é›†: {len(val_indices)} æ ·æœ¬")
            print(f"   æµ‹è¯•é›†: {len(test_indices)} æ ·æœ¬")
            print(f"ğŸ“Š æ€»åŠ è½½æ—¶é—´: {total_load_time:.2f}ç§’ (pkl: {pkl_load_time:.2f}s, æå–: {extract_time:.2f}s, åˆ’åˆ†: {split_time:.2f}s)")
        else:
            print(f"âœ… ä»ç¼“å­˜åŠ è½½ RadioML æ•°æ®é›† ({self.split})")
        
        # Get data from cache
        cached_data = _RADIOML_DATA_CACHE[cache_key]
        raw_data = cached_data['raw_data']
        modulation_to_label = cached_data['modulation_to_label']
        self.num_classes = cached_data['num_classes']
        
        # Select split
        if self.split == 'train':
            selected_indices = cached_data['train_indices']
        elif self.split == 'valid':
            selected_indices = cached_data['val_indices']
        elif self.split == 'test':
            selected_indices = cached_data['test_indices']
        else:
            raise ValueError(f"Unknown split: {self.split}")
        
        # åªæå–å½“å‰ split éœ€è¦çš„æ•°æ®
        print(f"   æ­£åœ¨æå– {self.split} æ•°æ®...")
        self.samples = []
        
        for key, idx, label in selected_indices:
            modulation, snr = key
            data = raw_data[key][idx].copy()  # å¤åˆ¶å•ä¸ªæ ·æœ¬
            
            self.samples.append({
                'data': data,
                'label': label,
                'modulation': modulation,
                'snr': snr
            })
        
        # æ‰“å°ä¿¡æ¯
        print(f"   {self.split} æ•°æ®é›†: {len(self.samples):,} æ ·æœ¬")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        """
        è·å–å•ä¸ªæ ·æœ¬
        è¿”å›æ ¼å¼ä¸ subDataset ä¿æŒä¸€è‡´ï¼š(å¤æ•°å¼ é‡, æ ‡ç­¾)
        """
        sample = self.samples[idx]
        data = sample['data']  # (2, 128)
        label = sample['label']
        
        # è½¬æ¢ä¸º float32
        data = data.astype(np.float32)
        
        # è½¬æ¢ä¸º PyTorch å¼ é‡
        data_real = torch.from_numpy(data[0])  # (128,)
        data_imag = torch.from_numpy(data[1])  # (128,)
        
        # è½¬æ¢ä¸ºå¤æ•°æ ¼å¼ï¼Œä¸ subDataset çš„è¾“å‡ºæ ¼å¼ä¸€è‡´
        out = torch.view_as_complex(torch.stack([data_real, data_imag], dim=-1))
        
        return out, label


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    pkl_path = r'E:\BaiduNet_Download\augmented_data.pkl'
    
    print("æµ‹è¯• RadioML æ•°æ®é›†åŠ è½½...")
    print("="*70)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = RadioMLDataset(datapath=pkl_path, split='train', transform=None, snr_filter=None)
    val_dataset = RadioMLDataset(datapath=pkl_path, split='valid', transform=None, snr_filter=None)
    test_dataset = RadioMLDataset(datapath=pkl_path, split='test', transform=None, snr_filter=None)
    
    print(f"\næ•°æ®é›†å¤§å°:")
    print(f"  è®­ç»ƒé›†: {len(train_dataset):,}")
    print(f"  éªŒè¯é›†: {len(val_dataset):,}")
    print(f"  æµ‹è¯•é›†: {len(test_dataset):,}")
    print(f"  ç±»åˆ«æ•°: {train_dataset.num_classes}")
    
    # æµ‹è¯•è¯»å–
    print(f"\næµ‹è¯•è¯»å–ç¬¬ä¸€ä¸ªæ ·æœ¬:")
    data, label = train_dataset[0]
    print(f"  æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"  æ•°æ®ç±»å‹: {data.dtype}")
    print(f"  æ ‡ç­¾: {label}")
    
    print("\nâœ… æµ‹è¯•é€šè¿‡ï¼")

